Ideas for the project:


- Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models
https://openreview.net/forum?id=BkxRRkSKwr

- FreeLB: Enhanced Adversarial Training for Language Understanding
https://openreview.net/forum?id=BygzbyHFvB

- Incorporating BERT into Neural Machine Translation
https://openreview.net/forum?id=Hyl7ygStwB

- TinyBERT: Distilling BERT for Natural Language Understanding
https://openreview.net/forum?id=rJx0Q6EFPB

- RoBERTa: A Robustly Optimized BERT Pretraining Approach
https://openreview.net/forum?id=SyxS0T4tvS

- StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
https://openreview.net/forum?id=BJgQ4lSFPH


- Deliberation Learning for Image-to-Image Translation
https://openreview.net/forum?id=Byg0B31MaH